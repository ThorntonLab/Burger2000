---
title: "Burger CH1, Sections 1-7"
author: "Kevin Thornton"
date: "April 5, 2017"
output:
  html_document: default
  pdf_document: default
---

# Hardy-Weinberg

## One locus, two alleles

There are three genotypes, $A_1A_1$, $A_1A_2$, and $A_2A_2$  The frequencies of the genotypes are $P$, $2PQ$, and RQ$, respectively.  The factor of two in the second term comes from there being to allele orderings that result in the heterozygote.

The main question is, "What is $P'$?", or "What is the frequency if $P$ in the next generation?". To make progress, we assume:

* Random mating
* No selection
* No further mutation
* autosomal locus
* no separate sexes

With these assumptions, changes in genotype frequency boil down to multiplying frequencies times the expected gamete ratios from Mendelian inheritance.  The relevant table is 2.1 on page 6.

For example, $$P' = P^2 \times 1 + 4PQ \times \frac{1}{2} + 2PR \times 0 + 4Q^2 \times \frac{1}{4} + 4QR \times 0 + R^2 \times 0,$$ which simplifies to $$P' = (P+Q)^2.$$

If we continue to another generation, we'll get $$P'' = (P'+Q')^2  =(P+Q)^2.$$

Thus, the genotype frequencies hit "HWE" in a single generation.  The allele frequencies are $p = f(A_1) = (P+Q)$ and $q = f(A_2) = (Q+R)$.

## Separate sexes, X linkage

These cases are curiosities, given that the book will likely never deal with selection in a way where this stuff matters.

For separate sexes, HWE is reached *within* each sex in one generation, and then within the entire population in generation two.

For X linkage, there's a harmonic convergence to HWE, where the deviation from HWE oscillates in sign each generation and converges rapidly, but requires $> 2$ generations.

## Multiple alleles

This will be important.  Later models in the book will involve multiple loci with multiple alleles per locus.

Alleles are $A_i, i \in 1, \ldots, k$ and genotypes $A_iA_j$ are unordered, giving frequency $2P_{ij}$.  Thus, the frequency of an allele is its marginal sum over genotypes, $$p_i = f(A_i) = \sum_{j=1}^kP_{ij}.$$

The book-keeping gets tedious.  The unordered genotype $A_iA_j$ can be the offspring of unordered matings $A_iA_k \times A_lA_j$, and the subscripts can take on several values representing homo- or hetero- zygous parental types:

* $A_iA_i \times A_jA_j$ with probability $2(P_{ii}P_{jj})$
* $A_iA_k \times A_jA_j$ with probability $2(2P_{ik}P_{jj})$
* $A_iA_i \times A_lA_j$ with probability $2(P_{ii}2P_{lj})$
* $A_iA_j \times A_iA_j$ with probability $2(2P_{ij}2P_{lj})$
* $A_iA_j \times A_iA_j$ with probability $2(2P_{ij}2P_{lj})$
* $A_jA_k \times A_lA_j$ with probability $2(2P_{jk}2P_{lj})$

For each of the above matings, the probability of an $A_iA_j$ offspring is 1, 1/2, 1/2, 1/2, and 1/4, respectively.  The unconditional probability of an $A_iA_j$ offspring therefor must sum over genotype frequencies: $$ 2P'_{ij} = 2P_{ii}P_{jj} + 2\sum_{k \neq i}P_{ik}P{lj} + 2\sum_{l \neq j}P_{ii}P_{lj} + 2P_{ij}^2 + 2\sum_{k \neq i}\sum_{l \neq j, (k,l)\neq (j,i)}P_{ik}P_{lj}.$$

The previous expression reduces to $P'_{ij} = p_ip_j$ for all $i$ and $j$.

# Variance components

## Definitions

$G_{ij}$ is the genetic value of genotype $A_iA_j$.  The mean genetic value is $$\bar G = \sum_{i,j}G_{ij}P_{ij}.$$  The deviation in genetic value from the mean for genotype $A_iA_j$ is $$g_{ij} = G_{ij}-\bar G,$$ which is sometimes called the "average excess" of the genotype.

The _total_ genetic variance is based on the _squared excesses_, _e.g._ $$\sigma_G^2 = \sum_{i,j}g_{ij}^2P_{ij}.$$

## Parents pass genes on to offspring, but not genetic values

This is example 1, page 11.

One locus, two alleles, and the pop is in HWE.  Genetic values are $G_{11} \neq G_{12} = G_{22},$ implying that $A_2$ is dominant.

What is $G'_{12}$ in the next generation amongst the offspring of $A_{12}$ individuals?  

\begin{align*}
G'_{12} &= Pr(\mathrm{mate\ is\ }A_{11})Pr(G\mathrm{\ values\ in\ offpsring}) + \ldots \\
 &= p^2(\frac{1}{2}G_{11} + \frac{1}{2}G_{12})+2pq(\frac{1}{4}G_{11}+\frac{1}{2}G_{12}+\frac{1}{4}G_{22})+q^2(\frac{1}{2}G_{12}+\frac{1}{2}G_{22})\\
 &= \frac{1}{2}pG_{11} + (1-\frac{1}{2}p)G_{22}
\end{align*}


But, the expected gentic value from $A_{22}$ offspring is $G_{22}$ due to the dominanace of $A_2$, and Medelian segregation complicates the relationship between offspring and parental genetic values.

## Fisher's least-squares approximation

In order to make progress, we have to get back to Fisher.  We're doing to define the average effect of an allele on genetic values.  Thus, allele $A_i$ on average contributes $\gamma_i$ to genetic values.  With this new notation the _average excess_ becomes $$g_{ij} = \gamma_i + \gamma_j + \upsilon_{ij}.$$  Here, $\nu_{ij}$ is the _dominance deviation_ from the mean trait value. The simple additive model is when $\upsilon_{ij} = 0.$

What we want to do is approximate $G_{ij}$ with the best-fit linear expression, $\bar G + \gamma_i + \gamma_j$.  To do this, we minimize the dominance variance, _e.g._ $$\sigma^2_D = \sum_{ij}\upsilon^2_{ij}P_{ij} = \sum_{ij}(g_{ij}-\gamma_i -\gamma_j)^2P_{ij}.$$  Taking the derivative with respect to $\gamma_i$ means that the minimization condition is $$ \sum_{j}\upsilon^2_{ij}P_{ij} = \sum_{j}(g_{ij}-\gamma_i -\gamma_j)P_{ij} = 0$$ for all $i$.

Getting to 3.8 is tricky--steps are skipped.  You take $\sum_{ij}g_{ij}P_{ij}$, and substitute a bunch of things.  The mean of the average effect of a mutation is seen to be 0.

Let's work thru example 2, which is one locus, two alleles, and HWE.  The mean genetic value is $$\bar G = G_{22} + 2(G_{12}+G_{22}) + 2\upsilon p^2.$$

To get 3.1.4, I wrote $$\bar G = p^2G_{11} + 2pqG_{12} + q^2G_{22}$$ and $$\upsilon = \frac{1}{2}(G_{11}+G_{22})-G_{12},$$ which yielded $$\bar G = pG_{11}+qG_{22}+2pq\upsilon$$ after simplification.  My expression seems numerically equivalent to his 3.14.

Burger's approach appears to follow this line of algebra. $$\bar G = p^2G_{11} + 2p(1-p)G_{12} + (1-p)^2G_{22}$$ Which can be expanded to $$\bar G = p^2G_{11} + 2pG_{12} - 2p^2G_{12} + G_{22} - 2pG_{22} + p^2G_{22}$$ We can then group the terms by their order in p $$\bar G = G_{22} +2p(G_{12} - G_{22})  + p^2(G_{11}+ G_{22} -2G_{12} )  $$ Then we substitute $$2\upsilon = (G_{11}+G_{22})-2G_{12}$$  into the previous line and get $$\bar G = G_{22} +2p(G_{12} - G_{22})  + 2\upsilon p^2 $$

The average effects of $A_1$ and $A_2$ are then gotten through brute-force substitution and simplification.  The algebra is tedious, but it puts you in a place to finally get 3.15 and 3.16.

The whole point of this exercise is 3.17.  The change in the $G$ terms now gives us offspring that differ from the population meant genetic value by half the additive effect of the parent, and the dominance terms aren't affecting that as they were before.


## The Kojima-Wright method for variance components

The paper by Kojima on the [Role of Epistasis and Overdominance in Stability Equilibria with Selection](https://www.ncbi.nlm.nih.gov/pubmed/16590492) shows a very useful method for deriving variance components from arbitary genetic models. This method has come back into use recently in a 2014 paper by Maki-Tanila and Hill in Genetics in on the [Influence of Gene Interaction on Complex Trait Variation with Multilocus Models](http://www.genetics.org/content/198/1/355).

We begin with the same expression for the population mean as we had earlier. $$\bar G = p^2G_{11} + 2p(1-p)G_{12} + (1-p)^2G_{22}$$ If instead we have multiple loci then for the $k^{th}$ locus we can write $$\bar G = p_k^2\bar G_{11,k} + 2p_k(1-p_k)\bar G_{12,k} + (1-p_k)^2\bar G_{22,k}$$
Where $\bar G_{11,k}$ is the expecation of genotype $G_{11}$ at the $k^{th}$ locus--the expectation being taken over the genotypes at all other loci.

The next step, coming from Wright, is too define the partial derivative of the population mean with respect to the allele frequency at the $k^{th}$ locus. It's straight forward derivative rules to see that $$\frac{\partial \bar G}{\partial p_k} = 2\alpha_{1,0,k} = 2(p_k(\bar G_{11,k} - \bar G_{12,k}) + (1-p_k)(\bar G_{12,k} - \bar G_{22,k})) $$ To tie this in to the derivations from the Burger book, I want to demonstrate that $$\alpha_{1,0,k} = (\gamma_{1,k} - \gamma_{2,k})$$ Which I can do assuming a biallelic locus in HWE, like example 2. In this case, due to equation 3.10 (remember $g_{12}=g_{21}$): 


\begin{align*}
\gamma_1 &= g_{11}p + g_{12}(1-p) \\ 
\gamma_2 &= g_{12}p + g_{22}(1-p)
\end{align*}

Therefore 


\begin{align*}
\gamma_1 - \gamma_2 &=  p(g_{11} - g_{12}) + (1-p)(g_{12} - g_{22}) \\ 
\gamma_1 - \gamma_2 &=  p((G_{11} - \bar G) - (G_{12} - \bar G)) + (1-p)( (G_{12} - \bar G)  - (G_{22} - \bar G)) \\ 
\gamma_1 - \gamma_2 &=  p(G_{11} - G_{12}) + (1-p)( G_{12}  - G_{22}) 
\end{align*}


And, by generalization to this being the $k^{th}$ locus and assuming we can take expectation with respect to other loci, due to HWE and linkage equilibrium $$\gamma_{1,k} - \gamma_{2,k} =  p( \bar G_{11,k} - \bar G_{12,k}) + (1-p)( \bar G_{12,k}  - \bar G_{22,k}) = \alpha_{1,0,k} $$ Now we know that the derivative of the population mean with respect to the allele frequency is equal to twice the average effect. We can then plug that into our previously derived expression for variance 

\begin{align*}
\sigma_{A}^2 &= 2p(1-p)(\gamma_1 - \gamma_2)^2 \\
\sigma_{A,k}^2 &= 2p(1-p)(\gamma_{1,k} - \gamma_{2,k})^2 \\
\sigma_{A,k}^2 &= 2p(1-p)\alpha_{1,0,k}^2 \\
\sigma_{A,k}^2 &= 2p(1-p)(\frac{1}{2}\frac{\partial \bar G}{\partial p_k})^2 
\end{align*}

Let's move onto the dominance variance, by taking the second derivative:


\begin{align*}
\frac{\partial \bar G}{\partial p_{k}^2} &= 2\alpha_{0,1,k} \\
 &= 2( \bar G_{11,k} - 2 \bar G_{12,k} + \bar G_{22,k})
\end{align*}

I wish to show that $\alpha_{0,1,k} = 2\upsilon_k$ which is pretty easy because $$ \alpha_{0,1,k} = \bar G_{11,k} + \bar G_{22,k} - 2 \bar G_{12,k} $$ and $$\upsilon_k = \frac{1}{2}(\bar G_{11,k} + \bar G_{12,k}) - \bar G_{12,k}$$ Burger showed in example 2 that the dominance variance is 

\begin{align*}
\sigma_{D}^2 &= 4\upsilon^2 p^2 (1-p)^2\\
\sigma_{D,k}^2 &= 4\upsilon_{k}^2 p_{k}^2 (1-p_{k})^2 \\
\sigma_{D,k}^2 &= (\alpha_{0,1,k})^2 p^2 (1-p)^2\\
\sigma_{D,k}^2 &=  p^2 (1-p)^2(\frac{1}{2}\frac{\partial \bar G}{\partial p_{k}^2})
\end{align*}


If you stare at these derivations long enough you will start to see a pattern. The order of the $\alpha_{L,Q,k}$ define the type of variance component as an L-additive by Q-dominance variance component. It is instructive to see a two locus example, so that you can see the  how epistative terms come about, however I defer to the Kojima paper for that.  Dominance is the highest order interaction that can exist in a single locus model, higher order variance components require taking partial derivative with respect to changing allele frequencies at multiple loci. It turns out the degree of additive variance is determined by how many first derivatives are taken and the degree of the dominance variance is determined by how many second derivatives. In general Kojima shows that


\begin{align*}
\alpha_{L,Q} &= \frac{1}{2^{L+Q}} \frac{\partial^{L+2Q} \bar G}{\prod_{j}^L \partial p_{j} \prod_{k}^{Q} \partial p_{k}^2} \;for\; j \neq k \\
\\
\sigma_{L,Q}^2 &= 2^{L}\prod_{j}^{L} p_j (1 - p_j) \prod_{k}^{Q}  p_{k}^2 (1 - p_k)^{2} (\alpha_{L,Q})^2
\end{align*}


Basically, this allows you to take really complicated multi locus models and derive algebraic expressions for their variance components. I have added a mathematica notebook illustrating how to do this for a two-locus model that looks relatively simple but ends up having really weird variance components.